### Hi there ðŸ‘‹
<!-- ### ä½ å¥½ðŸ‘‹ï¼Œæˆ‘æ˜¯è®¸èšå±• -->


<!-- ######################################################## -->

<!--
- ðŸ”­ Iâ€™m currently a Ph.D. student in Computer Science supervised by Prof. Ruizhen Hu, working in Visual Computing Research Center, Shenzhen University.
- ðŸŒ± I am interested in Computer Graphics, Robotics and Reinforcement Learning.
- ðŸªµ I am also interested in blender.

<h3>Research</h3>


<div style="width: 100%;">
<img src="paper.svg" style="width: 100%;">
</div>

-->
<div style='border: 1 solid red;'>
<img align='left' src="./assets/ibs_grasp/img.jpg" height='250' alt="å›¾ç‰‡" />

<div height='250'>
<h4>Learning High-DOF Reaching-and-Grasping via Dynamic Representation of Gripper-Object Interaction</h4>

<a href="#">Qijin She</a>, 
<a href="https://csse.szu.edu.cn/staff/ruizhenhu/index.htm">Ruizhen Hu</a>, 
Juzhan Xu, 
<a href="#">Min Liu</a>, 
<a href="http://kevinkaixu.net/">Kai Xu</a> and 
<a href="http://vcc.szu.edu.cn/~huihuang/">Hui Huang</a>

ACM Transactions on Graphics (Proc. SIGGRAPH), 41(4): 97, 2022.
[<a href="https://vcc.tech/research/2022/Grasping">Project page</a>]
<br/>
<p align='left'>We approach the problem of high-DOF reaching-and-grasping via learning joint planning of grasp and motion with deep reinforcement learning. To resolve the sample efficiency issue in learning the high-dimensional and complex control of dexterous grasping, we propose an effective representation of grasping state characterizing the spatial interaction between the gripper and the target object.</p>
<br/>
</div>

</div>
